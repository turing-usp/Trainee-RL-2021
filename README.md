<img src="img/title.png" width="100%" />

Boas vindas ao Projeto Trainee 2021 da área de Aprendizado por Reforço!

Antes de mais nada, recomendamos ler a seção de **[👩‍🏫 Introdução](https://github.com/turing-usp/Aprendizado-por-Reforco/tree/main/Introdu%C3%A7%C3%A3o)** do nosso Repositório de Aprendizado por Reforço, para se familiarizar com os conceitos principais da área!

O projeto será dividido em duas partes:

<img src="img/tarefa1.png" width="100%" />

Nessa primeira etapa do projeto você, construirá um agente simples de Aprendizado por Reforço para entender um pouco melhor os principais conceitos da área aplicados em algum tipo de código. Aqui você aprenderá sobre o que é o clássico problema dos *k*-Armed Bandits, como conseguir estimar valores para determinada ações com base na recompensa, como selecionar ações com esse maior valor estimado e como conseguir explorar o ambiente para que o agente descubra novas ações. Você também aprenderá como treinar esse agentes criados.

Para isso, recomendamos nosso **[📰 Turing Talks](https://medium.com/turing-talks/sua-primeira-ia-o-problema-dos-k-armed-bandits-cc63732567b2)** sobre e também a nossa implementação dele no nosso **[🎰 Repositório](https://github.com/turing-usp/Aprendizado-por-Reforco/tree/main/Aprendizado%20por%20Refor%C3%A7o%20Cl%C3%A1ssico/Bandits)**.

Comece agora mesmo acessando o notebook da [Tarefa 1 - Bandits](Tarefa%201%20-%20Bandits.ipynb)!

<img src="img/tarefa2.png" width="100%" />

Na segunda parte do projeto, você deverá implementar e comparar diferentes algoritmos de Aprendizado por Reforço Profundo utilizando a biblioteca [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/).

Este repositório já contém um tutorial simples de como utilizar a biblioteca, que você pode conferir **[aqui](Tutorial%20-%20Stable%20Baselines.ipynb)**!
