<img src="img/title.png" width="100%" />

Boas vindas ao Projeto Trainee 2021 da Ã¡rea de Aprendizado por ReforÃ§o!

Antes de mais nada, recomendamos ler a seÃ§Ã£o de **[ğŸ‘©â€ğŸ« IntroduÃ§Ã£o](https://github.com/turing-usp/Aprendizado-por-Reforco/tree/main/Introdu%C3%A7%C3%A3o)** do nosso RepositÃ³rio de Aprendizado por ReforÃ§o, para se familiarizar com os conceitos principais da Ã¡rea!

O projeto serÃ¡ dividido em duas partes:

<img src="img/tarefa1.png" width="100%" />

Nessa primeira etapa do projeto vocÃª, construirÃ¡ um agente simples de Aprendizado por ReforÃ§o para entender um pouco melhor os principais conceitos da Ã¡rea aplicados em algum tipo de cÃ³digo. Aqui vocÃª aprenderÃ¡ sobre o que Ã© o clÃ¡ssico problema dos *k*-Armed Bandits, como conseguir estimar valores para determinada aÃ§Ãµes com base na recompensa, como selecionar aÃ§Ãµes com esse maior valor estimado e como conseguir explorar o ambiente para que o agente descubra novas aÃ§Ãµes. VocÃª tambÃ©m aprenderÃ¡ como treinar esse agentes criados.

Para isso, recomendamos nosso **[ğŸ“° Turing Talks](https://medium.com/turing-talks/sua-primeira-ia-o-problema-dos-k-armed-bandits-cc63732567b2)** sobre e tambÃ©m a nossa implementaÃ§Ã£o dele no nosso **[ğŸ° RepositÃ³rio](https://github.com/turing-usp/Aprendizado-por-Reforco/tree/main/Aprendizado%20por%20Refor%C3%A7o%20Cl%C3%A1ssico/Bandits)**.

Comece agora mesmo acessando o notebook da [Tarefa 1 - Bandits](Tarefa%201%20-%20Bandits.ipynb)!

<img src="img/tarefa2.png" width="100%" />

Na segunda parte do projeto, vocÃª deverÃ¡ implementar e comparar diferentes algoritmos de Aprendizado por ReforÃ§o Profundo utilizando a biblioteca [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/).

Este repositÃ³rio jÃ¡ contÃ©m um tutorial simples de como utilizar a biblioteca, que vocÃª pode conferir **[aqui](Tutorial%20-%20Stable%20Baselines.ipynb)**!
