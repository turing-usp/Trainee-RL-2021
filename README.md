<img src="img/title.png" width="100%" />

Boas vindas ao Projeto Trainee 2021 da √°rea de Aprendizado por Refor√ßo!

Antes de mais nada, recomendamos ler a se√ß√£o de **[üë©‚Äçüè´ Introdu√ß√£o](https://github.com/turing-usp/Aprendizado-por-Reforco/tree/main/Introdu%C3%A7%C3%A3o)** do nosso Reposit√≥rio de Aprendizado por Refor√ßo para se familiarizar com os conceitos principais da √°rea!

O projeto ser√° dividido em duas partes:

<img src="img/tarefa1.png" width="100%" />

Nessa primeira etapa do projeto, voc√™ construir√° um agente simples de Aprendizado por Refor√ßo para entender um pouco melhor os principais conceitos da √°rea aplicados em algum tipo de c√≥digo. Aqui, voc√™ aprender√° sobre o cl√°ssico problema dos *k*-Armed Bandits, como conseguir estimar valores para determinada a√ß√µes com base na recompensa, como selecionar a√ß√µes com esse maior valor estimado e como conseguir explorar o ambiente para que o agente descubra novas a√ß√µes. Voc√™ tamb√©m aprender√° como treinar esse agentes criados.

Para isso, recomendamos nosso **[üì∞ Turing Talks](https://medium.com/turing-talks/sua-primeira-ia-o-problema-dos-k-armed-bandits-cc63732567b2)** sobre o assunto e tamb√©m a nossa implementa√ß√£o dele no nosso **[üé∞ Reposit√≥rio](https://github.com/turing-usp/Aprendizado-por-Reforco/tree/main/Aprendizado%20por%20Refor%C3%A7o%20Cl%C3%A1ssico/Bandits)**.

Comece agora mesmo acessando o notebook da [Tarefa 1 - Bandits](Tarefa%201%20-%20Bandits.ipynb)!

<img src="img/tarefa2.png" width="100%" />

Na segunda parte do projeto, voc√™ dever√° implementar e comparar diferentes algoritmos de Aprendizado por Refor√ßo Profundo utilizando a biblioteca [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/).

Este reposit√≥rio j√° cont√©m um tutorial simples de como utilizar a biblioteca, que voc√™ pode conferir **[aqui](Tutorial%20-%20Stable%20Baselines.ipynb)**!

Para come√ßar a tarefa, basta acessar e alterar **[este notebook](Tarefa%202%20-%20Stable%20Baselines.ipynb)**!

<img src="img/tarefa_extra.png" width="100%" />

Por fim, propomos uma tarefa extra 100% opcional caso queira treinar suas habilidades de RL! Ao final do projeto Trainee, caso seja interessante, voc√™ pode optar por treinar um novo modelo para o ambiente **slime-volleyball**, um jogo de v√¥lei no qual seu agente pode competir com os jogadores de outros membros.

Para treinar seu pr√≥prio agente, basta apenas rodar [este Jupyter Notebook](https://colab.research.google.com/drive/1hzRhoJ8UuBs-rK8DID3l85k-8Z8MxqXL#forceEdit=true&sandboxMode=true) em seu Google Colaboratory. Recomendamos, antes de come√ßar, conversar com algum dos veteranos da √°rea, copiar o notebook para seu drive e editar os hiperpar√¢metros conforme necess√°rio!

**DISCLAMER:** Os agentes de v√¥lei demorar√£o muitas horas (3+) para serem treinados e nem sempre superar√£o a IA j√° programada no pr√≥prio jogo, ent√£o n√£o se desanime caso n√£o esteja obtendo resultados r√°pidos! Lembrando que esta √© uma tarefa **100% opcional**.